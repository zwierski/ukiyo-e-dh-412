{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marga\\AppData\\Local\\Temp\\ipykernel_21508\\1436364997.py:2: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nouns = pd.read_csv('./text_processing/labels.csv')\n"
     ]
    }
   ],
   "source": [
    "prints = pd.read_csv('./ukiyo-e_crawler/meta_data/ukiyo-e_artworks_details.csv').reset_index()\n",
    "nouns = pd.read_csv('./text_processing/labels.csv')\n",
    "nouns = nouns[['Unnamed: 0', 'LABELS']].rename(columns={'Unnamed: 0': 'index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Details</th>\n",
       "      <th>Source</th>\n",
       "      <th>Description</th>\n",
       "      <th>Similar Prints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://data.ukiyo-e.org/bm/scaled/AN00418884_...</td>\n",
       "      <td>Okumura Masanobu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711</td>\n",
       "      <td>https://www.britishmuseum.org/collection/objec...</td>\n",
       "      <td>http://www.britishmuseum.org/research/search_t...</td>\n",
       "      <td>Print. Sixth of series of twelve (first two mi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          Image URL            Artist  \\\n",
       "0      0  https://data.ukiyo-e.org/bm/scaled/AN00418884_...  Okumura Masanobu   \n",
       "\n",
       "  Title  Date                                            Details  \\\n",
       "0   NaN  1711  https://www.britishmuseum.org/collection/objec...   \n",
       "\n",
       "                                              Source  \\\n",
       "0  http://www.britishmuseum.org/research/search_t...   \n",
       "\n",
       "                                         Description Similar Prints  \n",
       "0  Print. Sixth of series of twelve (first two mi...             []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(prints))\n",
    "prints.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['print', 'sixth', 'series', 'twelve', 'first'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             LABELS\n",
       "0      0  ['print', 'sixth', 'series', 'twelve', 'first'..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(nouns))\n",
    "nouns.head(1) # the lengths do not match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177939\n"
     ]
    }
   ],
   "source": [
    "prints_with_nouns = prints.merge(nouns, on='index') # this is problematic: \n",
    "# if i merge on linear index, some works won't be associated with the correct description... \n",
    "# i would need something else in labels.csv to merge on, such as the title\n",
    "print(len(prints_with_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Details</th>\n",
       "      <th>Source</th>\n",
       "      <th>Description</th>\n",
       "      <th>Similar Prints</th>\n",
       "      <th>LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177982</th>\n",
       "      <td>177982</td>\n",
       "      <td>https://data.ukiyo-e.org/artelino/scaled/31208...</td>\n",
       "      <td>Kusaka Kenji</td>\n",
       "      <td>Mt.Fuji is seen around Miya</td>\n",
       "      <td>1949.</td>\n",
       "      <td>http://www.artelino.com/archive/archivesearch_...</td>\n",
       "      <td>http://artelino.com/</td>\n",
       "      <td>\"Fuji Miya Fukin\". Mt. Fuji is seen from the a...</td>\n",
       "      <td>['https://ukiyo-e.org/image/artelino/19069g1',...</td>\n",
       "      <td>['see', 'area', 'near', 'see', 'around']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177983</th>\n",
       "      <td>177983</td>\n",
       "      <td>https://data.ukiyo-e.org/artelino/scaled/50236...</td>\n",
       "      <td>Kusaka Kenji</td>\n",
       "      <td>Kiyomizu Temple</td>\n",
       "      <td>1948..</td>\n",
       "      <td>http://www.artelino.com/archive/archivesearch_...</td>\n",
       "      <td>http://artelino.com/</td>\n",
       "      <td>The performance platform of Kiyomizu temple in...</td>\n",
       "      <td>['https://ukiyo-e.org/image/jaodb/Kawai_Kenji-...</td>\n",
       "      <td>['performance', 'platform', 'temple', 'autumn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177984</th>\n",
       "      <td>177984</td>\n",
       "      <td>https://data.ukiyo-e.org/artelino/scaled/15906...</td>\n",
       "      <td>Kusaka Kenji</td>\n",
       "      <td>Ski Slope in Akino</td>\n",
       "      <td>Ca. 1950s.</td>\n",
       "      <td>http://www.artelino.com/archive/archivesearch_...</td>\n",
       "      <td>http://artelino.com/</td>\n",
       "      <td>Ski Slope in Akino.</td>\n",
       "      <td>['https://ukiyo-e.org/image/jaodb/Kawai_Kenji-...</td>\n",
       "      <td>['ski', 'slope', 'ski', 'slope']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                          Image URL  \\\n",
       "177982      177982  https://data.ukiyo-e.org/artelino/scaled/31208...   \n",
       "177983      177983  https://data.ukiyo-e.org/artelino/scaled/50236...   \n",
       "177984      177984  https://data.ukiyo-e.org/artelino/scaled/15906...   \n",
       "\n",
       "              Artist                        Title        Date  \\\n",
       "177982  Kusaka Kenji  Mt.Fuji is seen around Miya       1949.   \n",
       "177983  Kusaka Kenji              Kiyomizu Temple      1948..   \n",
       "177984  Kusaka Kenji           Ski Slope in Akino  Ca. 1950s.   \n",
       "\n",
       "                                                  Details  \\\n",
       "177982  http://www.artelino.com/archive/archivesearch_...   \n",
       "177983  http://www.artelino.com/archive/archivesearch_...   \n",
       "177984  http://www.artelino.com/archive/archivesearch_...   \n",
       "\n",
       "                      Source  \\\n",
       "177982  http://artelino.com/   \n",
       "177983  http://artelino.com/   \n",
       "177984  http://artelino.com/   \n",
       "\n",
       "                                              Description  \\\n",
       "177982  \"Fuji Miya Fukin\". Mt. Fuji is seen from the a...   \n",
       "177983  The performance platform of Kiyomizu temple in...   \n",
       "177984                                Ski Slope in Akino.   \n",
       "\n",
       "                                           Similar Prints  \\\n",
       "177982  ['https://ukiyo-e.org/image/artelino/19069g1',...   \n",
       "177983  ['https://ukiyo-e.org/image/jaodb/Kawai_Kenji-...   \n",
       "177984  ['https://ukiyo-e.org/image/jaodb/Kawai_Kenji-...   \n",
       "\n",
       "                                                   LABELS  \n",
       "177982           ['see', 'area', 'near', 'see', 'around']  \n",
       "177983  ['performance', 'platform', 'temple', 'autumn'...  \n",
       "177984                   ['ski', 'slope', 'ski', 'slope']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_data = pd.read_csv(\"./ukiyo-e_artworks_labels.csv\")\n",
    "print(len(test_full_data))\n",
    "test_full_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "test_full_data['LABELS'] = test_full_data['LABELS'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emperor': 699, 'shogun': 335, 'government officials': 0, 'voting': 0, 'constitution': 31, 'courtroom': 0, 'legal document': 0, 'contracts': 0, 'patent': 120, 'judge': 47, 'lawyer': 0, 'police': 40, 'prison': 9, 'school': 282, 'school uniform': 0, 'textbooks': 0, 'scientific instrument': 0, 'steamship': 16, 'telegraph poles': 0, 'brick house': 0, 'factory': 21, 'steam-powered machinery': 0, 'worker': 102, 'railway': 45, 'train': 85, 'train station': 0, 'soldier': 213, 'gun': 98, 'military uniform': 0, 'warship': 30, 'kimono': 1372, 'western style clothing': 0, 'gloves': 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "keywords = ['Emperor', 'Shogun', 'Government officials', 'Voting', 'Constitution',\n",
    "              'Courtroom', 'Legal document', 'Contracts', 'Patent', 'Judge', 'Lawyer','Police', 'Prison',\n",
    "              'School', 'School uniform', 'Textbooks', 'Scientific instrument',\n",
    "              'Steamship', 'Telegraph poles', 'Brick house',\n",
    "              'Factory', 'Steam-powered machinery', 'Worker', 'Railway', 'Train', 'Train station',\n",
    "              'Soldier', 'Gun', 'Military uniform', 'Warship',\n",
    "              'Kimono', 'Western style clothing', 'Gloves']\n",
    "\n",
    "keywords = [x.lower() for x in keywords]\n",
    "\n",
    "test = test_full_data.iloc[0]['LABELS']\n",
    "\n",
    "def kw_in_labels(labels):\n",
    "    res = {k: 0 for k in keywords}\n",
    "    for l in labels:\n",
    "        if (l in keywords):\n",
    "            res[l] = res[l] + 1\n",
    "    return res\n",
    "\n",
    "test_full_data['kws'] = test_full_data['LABELS'].apply(lambda x: kw_in_labels(x))\n",
    "# print(len(test_full_data[test_full_data['kws']==True]))\n",
    "test_full_data[['LABELS', 'kws']].head()\n",
    "\n",
    "\n",
    "full_res = {k: 0 for k in keywords}\n",
    "\n",
    "# make the huge dictionary\n",
    "for _, d in test_full_data.iterrows():\n",
    "    dico = d.kws\n",
    "    for k in keywords:\n",
    "        full_res[k] = full_res[k] + dico[k]\n",
    "\n",
    "print(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emperor': 699, 'shogun': 335, 'minister': 65, 'vote': 0, 'constitution': 31, 'courtroom': 0, 'contract': 17, 'patent': 120, 'judge': 47, 'lawyer': 0, 'police': 40, 'prison': 9, 'school': 282, 'uniform': 33, 'textbook': 4, 'scientific instrument': 0, 'steamship': 16, 'telegraph': 9, 'brick': 24, 'factory': 21, 'steam': 73, 'worker': 102, 'railway': 45, 'train': 85, 'soldier': 213, 'gun': 98, 'warship': 30, 'kimono': 1372, 'suit': 42, 'gown': 28, 'glove': 12}\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Emperor', 'Shogun', 'Minister', 'Vote', 'Constitution',\n",
    "              'Courtroom', 'Contract', 'Patent', 'Judge', 'Lawyer', 'Police', 'Prison',\n",
    "              'School', 'Uniform', 'Textbook', 'Scientific instrument',\n",
    "              'Steamship', 'Telegraph', 'Brick',\n",
    "              'Factory', 'Steam', 'Worker', 'Railway', 'Train',\n",
    "              'Soldier', 'Gun', 'Warship',\n",
    "              'Kimono', 'Suit', 'Gown', 'Glove']\n",
    "\n",
    "keywords = [x.lower() for x in keywords]\n",
    "\n",
    "test_full_data['kws2'] = test_full_data['LABELS'].apply(lambda x: kw_in_labels(x))\n",
    "test_full_data[['LABELS', 'kws2']].head()\n",
    "\n",
    "full_res = {k: 0 for k in keywords}\n",
    "\n",
    "# make the huge dictionary\n",
    "for _, d in test_full_data.iterrows():\n",
    "    dico = d.kws2\n",
    "    for k in keywords:\n",
    "        full_res[k] = full_res[k] + dico[k]\n",
    "\n",
    "print(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_per_image = test_full_data[['kws2']]\n",
    "type(dico_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marga\\Documents\\ukiyo-e-dh-412\\image_level_annotation.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marga/Documents/ukiyo-e-dh-412/image_level_annotation.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m dico_per_image\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marga/Documents/ukiyo-e-dh-412/image_level_annotation.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m d[\u001b[39m'\u001b[39m\u001b[39mkws2\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marga/Documents/ukiyo-e-dh-412/image_level_annotation.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         word_matrix[k]\u001b[39m.\u001b[39mloc[i] \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mkws2\u001b[39m\u001b[39m'\u001b[39m][k]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marga/Documents/ukiyo-e-dh-412/image_level_annotation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m word_matrix\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\indexing.py:1693\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\indexing.py:1944\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1942\u001b[0m \u001b[39m# actually do the set\u001b[39;00m\n\u001b[0;32m   1943\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39msetitem(indexer\u001b[39m=\u001b[39mindexer, value\u001b[39m=\u001b[39mvalue)\n\u001b[1;32m-> 1944\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_maybe_update_cacher(clear\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\series.py:1279\u001b[0m, in \u001b[0;36mSeries._maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy, inplace)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cacher\n\u001b[0;32m   1275\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(ref) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m ref\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m   1276\u001b[0m     \u001b[39m# GH#42530 self.name must be in ref.columns\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m     \u001b[39m# to ensure column still in dataframe\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m     \u001b[39m# otherwise, either self or ref has swapped in new arrays\u001b[39;00m\n\u001b[1;32m-> 1279\u001b[0m     ref\u001b[39m.\u001b[39;49m_maybe_cache_changed(cacher[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m, inplace\u001b[39m=\u001b[39;49minplace)\n\u001b[0;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[39m# GH#33675 we have swapped in a new array, so parent\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m     \u001b[39m#  reference to self is now invalid\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     ref\u001b[39m.\u001b[39m_item_cache\u001b[39m.\u001b[39mpop(cacher[\u001b[39m0\u001b[39m], \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\frame.py:3956\u001b[0m, in \u001b[0;36mDataFrame._maybe_cache_changed\u001b[1;34m(self, item, value, inplace)\u001b[0m\n\u001b[0;32m   3952\u001b[0m \u001b[39mif\u001b[39;00m old\u001b[39m.\u001b[39m_values \u001b[39mis\u001b[39;00m value\u001b[39m.\u001b[39m_values \u001b[39mand\u001b[39;00m inplace:\n\u001b[0;32m   3953\u001b[0m     \u001b[39m# GH#46149 avoid making unnecessary copies/block-splitting\u001b[39;00m\n\u001b[0;32m   3954\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m-> 3956\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49miset(loc, arraylike, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1133\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Accessing public blknos ensures the public versions are initialized\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m blknos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos[loc]\n\u001b[1;32m-> 1133\u001b[0m blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblklocs[loc]\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m   1135\u001b[0m unfit_mgr_locs \u001b[39m=\u001b[39m []\n\u001b[0;32m   1136\u001b[0m unfit_val_locs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_matrix = pd.DataFrame(index=np.arange(len(dico_per_image)), columns=full_res.keys())\n",
    "\n",
    "for i, d in dico_per_image.iterrows():\n",
    "    for k in d['kws2'].keys():\n",
    "        word_matrix[k].loc[i] = d['kws2'][k]\n",
    "\n",
    "word_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, two things to do:\n",
    "\n",
    "- Calculate similarity (find package, and get similarity from the word_matrix I'm creating)\n",
    "- Merge the full_test_data with the time dataframe, and for each keyword in the kws, create a graph showing time evolution of the word's appearance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
